{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43cff0c-91e0-4ed4-868f-ebcbc3f1db4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('Asia/Shanghai')}\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('6443'), PosixPath('https'), PosixPath('//u200987-98ae-aa95c268.neimeng.seetacloud.com')}\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('autodl-tmp/pubmed/2d907baf-8da5-40d6-bb3e-1e9ca4c944f5')}\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import scipy\n",
    "from torch_geometric.data import Data\n",
    "from torch_sparse import SparseTensor\n",
    "from tqdm import tqdm\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, LoraModel, PeftConfig, PeftModel\n",
    "import os\n",
    "import pickle\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import einsum\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8370e614-30e8-4c53-9ec3-358e901e88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# adapted from https://github.com/jcatw/scnn\n",
    "import torch\n",
    "import random\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# return pubmed dataset as pytorch geometric Data object together with 60/20/20 split, and list of pubmed IDs\n",
    "\n",
    "\n",
    "def get_pubmed_casestudy(corrected=False, SEED=0):\n",
    "    _, data_X, data_Y, data_pubid, data_edges = parse_pubmed()\n",
    "    data_X = normalize(data_X, norm=\"l1\")\n",
    "\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "    np.random.seed(SEED)  # Numpy module.\n",
    "    random.seed(SEED)  # Python random module.\n",
    "\n",
    "    # load data\n",
    "    data_name = 'PubMed'\n",
    "    # path = osp.join(osp.dirname(osp.realpath(__file__)), 'dataset')\n",
    "    dataset = Planetoid('dataset', data_name, transform=T.NormalizeFeatures())\n",
    "    data = dataset[0]\n",
    "\n",
    "    # replace dataset matrices with the PubMed-Diabetes data, for which we have the original pubmed IDs\n",
    "    data.x = torch.tensor(data_X)\n",
    "    data.edge_index = torch.tensor(data_edges)\n",
    "    data.y = torch.tensor(data_Y)\n",
    "\n",
    "    # split data\n",
    "    node_id = np.arange(data.num_nodes)\n",
    "    np.random.shuffle(node_id)\n",
    "\n",
    "    data.train_id = np.sort(node_id[:int(data.num_nodes * 0.6)])\n",
    "    data.val_id = np.sort(\n",
    "        node_id[int(data.num_nodes * 0.6):int(data.num_nodes * 0.8)])\n",
    "    data.test_id = np.sort(node_id[int(data.num_nodes * 0.8):])\n",
    "\n",
    "    if corrected:\n",
    "        is_mistake = np.loadtxt(\n",
    "            'pubmed_casestudy/pubmed_mistake.txt', dtype='bool')\n",
    "        data.train_id = [i for i in data.train_id if not is_mistake[i]]\n",
    "        data.val_id = [i for i in data.val_id if not is_mistake[i]]\n",
    "        data.test_id = [i for i in data.test_id if not is_mistake[i]]\n",
    "\n",
    "    data.train_mask = torch.tensor(\n",
    "        [x in data.train_id for x in range(data.num_nodes)])\n",
    "    data.val_mask = torch.tensor(\n",
    "        [x in data.val_id for x in range(data.num_nodes)])\n",
    "    data.test_mask = torch.tensor(\n",
    "        [x in data.test_id for x in range(data.num_nodes)])\n",
    "\n",
    "    return data, data_pubid\n",
    "\n",
    "\n",
    "def parse_pubmed():\n",
    "    path = 'data/'\n",
    "\n",
    "    n_nodes = 19717\n",
    "    n_features = 500\n",
    "\n",
    "    data_X = np.zeros((n_nodes, n_features), dtype='float32')\n",
    "    data_Y = [None] * n_nodes\n",
    "    data_pubid = [None] * n_nodes\n",
    "    data_edges = []\n",
    "\n",
    "    paper_to_index = {}\n",
    "    feature_to_index = {}\n",
    "\n",
    "    # parse nodes\n",
    "    with open(path + 'Pubmed-Diabetes.NODE.paper.tab', 'r') as node_file:\n",
    "        # first two lines are headers\n",
    "        node_file.readline()\n",
    "        node_file.readline()\n",
    "\n",
    "        k = 0\n",
    "\n",
    "        for i, line in enumerate(node_file.readlines()):\n",
    "            items = line.strip().split('\\t')\n",
    "\n",
    "            paper_id = items[0]\n",
    "            data_pubid[i] = paper_id\n",
    "            paper_to_index[paper_id] = i\n",
    "\n",
    "            # label=[1,2,3]\n",
    "            label = int(items[1].split('=')[-1]) - \\\n",
    "                1  # subtract 1 to zero-count\n",
    "            data_Y[i] = label\n",
    "\n",
    "            # f1=val1 \\t f2=val2 \\t ... \\t fn=valn summary=...\n",
    "            features = items[2:-1]\n",
    "            for feature in features:\n",
    "                parts = feature.split('=')\n",
    "                fname = parts[0]\n",
    "                fvalue = float(parts[1])\n",
    "\n",
    "                if fname not in feature_to_index:\n",
    "                    feature_to_index[fname] = k\n",
    "                    k += 1\n",
    "\n",
    "                data_X[i, feature_to_index[fname]] = fvalue\n",
    "\n",
    "    # parse graph\n",
    "    data_A = np.zeros((n_nodes, n_nodes), dtype='float32')\n",
    "\n",
    "    with open(path + 'Pubmed-Diabetes.DIRECTED.cites.tab', 'r') as edge_file:\n",
    "        # first two lines are headers\n",
    "        edge_file.readline()\n",
    "        edge_file.readline()\n",
    "\n",
    "        for i, line in enumerate(edge_file.readlines()):\n",
    "\n",
    "            \n",
    "            # edge_id \\t paper:tail \\t | \\t paper:head\n",
    "            items = line.strip().split('\\t')\n",
    "\n",
    "            edge_id = items[0]\n",
    "\n",
    "            tail = items[1].split(':')[-1]\n",
    "            head = items[3].split(':')[-1]\n",
    "\n",
    "            data_A[paper_to_index[tail], paper_to_index[head]] = 1.0\n",
    "            data_A[paper_to_index[head], paper_to_index[tail]] = 1.0\n",
    "            if head != tail:\n",
    "                data_edges.append(\n",
    "                    (paper_to_index[head], paper_to_index[tail]))\n",
    "                data_edges.append(\n",
    "                    (paper_to_index[tail], paper_to_index[head]))\n",
    "\n",
    "    return data_A, data_X, data_Y, data_pubid, np.unique(data_edges, axis=0).transpose()\n",
    "\n",
    "\n",
    "def get_raw_text_pubmed(use_text=False, seed=0):\n",
    "    data, data_pubid = get_pubmed_casestudy(SEED=seed)\n",
    "    if not use_text:\n",
    "        return data, None\n",
    "\n",
    "    f = open('pubmed.json')\n",
    "    pubmed = json.load(f)\n",
    "    df_pubmed = pd.DataFrame.from_dict(pubmed)\n",
    "\n",
    "    AB = df_pubmed['AB'].fillna(\"\")\n",
    "    TI = df_pubmed['TI'].fillna(\"\")\n",
    "    text = []\n",
    "    for ti, ab in zip(TI, AB):\n",
    "        t = 'Title: ' + ti + '\\n'+'Abstract: ' + ab\n",
    "        text.append(t)\n",
    "    return data, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba48b0f7-c203-4d51-8ae1-6ce0bcd14459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open('pubmed.json')\n",
    "pubmed = json.load(f)\n",
    "df_pubmed = pd.DataFrame.from_dict(pubmed)\n",
    "\n",
    "AB = df_pubmed['AB'].fillna(\"\")\n",
    "TI = df_pubmed['TI'].fillna(\"\")\n",
    "text = []\n",
    "for ti, ab in zip(TI, AB):\n",
    "    # t = 'Title: ' + ti + '\\n'+'Abstract: ' + ab\n",
    "    t = 'Title: ' + ti\n",
    "    text.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98200a8-7736-4cc3-ad05-61608df896f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78468582-651e-4b7a-b950-abce7fa748eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/root/miniconda3/envs/edgetoken/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.20s/it]\n"
     ]
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "                                    '../llama2-7b-hf',\n",
    "                                    load_in_8bit=True,\n",
    "                                    torch_dtype=torch.float16,\n",
    "                                    use_safetensors=False,\n",
    "                                    device_map='cuda:0'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3820c5e1-4546-4b7f-9443-fc85fc276670",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained('../llama2-7b-hf', max_length=4096)\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158acb66-6327-4d08-81b6-5009909906fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b00bc8a4-c6f8-437e-b981-735b4f8a0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = [\n",
    "#     f\"This sentence: \\\"{x}\\\" means in a word:\" for x in text\n",
    "# ]\n",
    "content=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a43f6-c66b-46ea-8ac0-906f99449ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6e7ab-2263-457b-ae66-623961f95c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064474dc-6575-4fd0-b9f1-0ae0dfff7a60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 19717/19717 [01:02<00:00, 316.06it/s]\n"
     ]
    }
   ],
   "source": [
    "edge_weights = []\n",
    "\n",
    "batch_size = 1  # 根据实际情况调整批次大小\n",
    "\n",
    "with torch.no_grad():  # 关闭梯度计算，减少显存使用\n",
    "    for i in tqdm(range(0, len(content), batch_size), desc=\"Processing batches\"):\n",
    "        batch_texts = []\n",
    "        for j in range(i, min(i + batch_size, len(content))):\n",
    "            # 获取节点中的tokens\n",
    "            batch_texts.append(content[j])\n",
    "        # 批量处理\n",
    "        batch_encoding = tokenizer(batch_texts, padding='longest', max_length=512, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "        input_ids = batch_encoding['input_ids'][:,1:]\n",
    "        attention_mask = batch_encoding['attention_mask'][:,1:]\n",
    "\n",
    "        # 计算每个句子嵌入的最终隐藏状态\n",
    "        # outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        # sentence_embeddings = outputs.hidden_states[-1][:, -1, :].cpu()\n",
    "        embeddings = model.model.embed_tokens(input_ids)\n",
    "        sentence_embeddings=torch.mean(embeddings,dim=1).cpu()\n",
    "\n",
    "        # 保存结果并释放内存\n",
    "        edge_weights.extend(sentence_embeddings)\n",
    "        # del input_ids, attention_mask, outputs\n",
    "        # del input_ids, attention_mask\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc59521-ed94-4e3a-a10d-dc5740ee6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为张量\n",
    "edge_weights = torch.stack(edge_weights)\n",
    "edge_weights=edge_weights.float() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5593b858-e4f4-43c2-8e1c-3d5a52ac58cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b949a4-a517-44b5-baec-9833bc39df1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Diabetes Mellitus, Experimental',\n",
       " 'Diabetes Mellitus Type 1',\n",
       " 'Diabetes Mellitus Type 2')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"Diabetes Mellitus, Experimental\", \"Diabetes Mellitus Type 1\", \"Diabetes Mellitus Type 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94504f1-a291-4332-8dab-c25a8f3c62a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e0684b5-edfa-42f2-8a87-f7ae0103c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A, data_X, data_Y, data_pubid, data_edges = parse_pubmed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f5ffae5-0233-4f05-9103-5269e35e8ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Retinal metabolic abnormalities in diabetic mouse: comparison with diabetic rat.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470d10b-f40e-4afa-a5bb-eaa71062f14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e176225-e3b3-4b23-933f-74d119f04e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e552859-31ab-4619-9f1d-c1ca48226699",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_t= SparseTensor(row=torch.tensor(data_edges[0]).to(torch.long), \n",
    "col=torch.tensor(data_edges[1]).to(torch.long),\n",
    "sparse_sizes=(len(data_Y),len(data_Y) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc3f81-6fb5-4e80-812d-845c629a295f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d329410-c133-4f04-853c-87c9151b1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= Data(x=edge_weights, adj_t=adj_t,y=torch.tensor(data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42bd0ca2-8c1e-433f-a7a7-bfe0b2c7d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f8d6e65-ead5-4d1f-a4e9-358ddb75f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2980dc30-337f-4abf-99f5-e10917740532",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = np.arange(data.num_nodes)\n",
    "np.random.shuffle(node_id)\n",
    "\n",
    "data.train_id = np.sort(node_id[:int(data.num_nodes * 0.6)])\n",
    "data.val_id = np.sort(\n",
    "    node_id[int(data.num_nodes * 0.6):int(data.num_nodes * 0.8)])\n",
    "data.test_id = np.sort(node_id[int(data.num_nodes * 0.8):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555508cc-7579-44be-b9d2-e827afad3c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1212b13c-8445-4a1d-b1ab-b002f4edc492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[19717, 4096], y=[19717], adj_t=[19717, 19717, nnz=88648], train_id=[11830], val_id=[3943], test_id=[3944])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996225fa-2e1f-4d79-a809-e6248e0341e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data, 'data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72fe78-2573-4fff-931c-5e8ba6ef0ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4aa14-2bb6-48d6-9919-ad5a0db22746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edgetoken",
   "language": "python",
   "name": "edgetoken"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
